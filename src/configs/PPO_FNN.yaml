---
# run info
n_episodes: 50
seed: 42
n_workers: 2
max_optimisation_steps: 1000

# Learner Config
learner_config: 
    run_name: "FNN_cooperative_pong"
    max_steps: 10000
    max_steps_per_episode: 900
    target_updates: 100
    samples_per_update: 512
    batch_size: 256
    IS: false
    log_interval: 10
    n_workers: 2
    optimiser_config:
      type: "adam"
      learning_rate: 3e-4
    n_epochs_update: 5
    

# Controller Config
controller_config: 
    action_size: 3
    gae_horizon: 16
    gamma: 0.995
    lam: 0.95
    clip_epsilon: 0.15
    value_loss_coefficient: 0.75
    entropy_coefficient: 0.01
    tau: 0.99
    n_features: 12
    actor_config:
      type: "FNN"
      layer_sizes: 
      - 512
      - 256
      - 128
    critic_config:
      type: "FNN"
      layer_sizes: 
      - 256
      - 128


# Environment Config
environment_config:
    type: pettingzoo
    module: pettingzoo.butterfly.cooperative_pong_v5
    env_fn: parallel_env
    env_kwargs:
        max_cycles: 900
        left_paddle_speed: 12
        right_paddle_speed: 12
        ball_speed: 9
        cake_paddle: true
        bounce_randomness: false
        max_reward: 100
        off_screen_penalty: -10
        render_mode: null
